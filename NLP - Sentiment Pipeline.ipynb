{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "import unidecode\n",
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score,confusion_matrix,plot_confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier,AdaBoostClassifier\n",
    "import xgboost\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import seaborn as sns\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sklearn import preprocessing\n",
    "from bs4 import BeautifulSoup\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday off Rick Steve recommendation and loved it.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so were the prices.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                  Sentence  \\\n",
       "0                                                                 Wow... Loved this place.   \n",
       "1                                                                       Crust is not good.   \n",
       "2                                                Not tasty and the texture was just nasty.   \n",
       "3  Stopped by during the late May bank holiday off Rick Steve recommendation and loved it.   \n",
       "4                              The selection on the menu was great and so were the prices.   \n",
       "\n",
       "   Polarity  \n",
       "0         1  \n",
       "1         0  \n",
       "2         0  \n",
       "3         1  \n",
       "4         1  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"datasets/sentiment_train.csv\")\n",
    "pd.set_option('display.max_colwidth',None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentence    0\n",
       "Polarity    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "#checking for blank spaces\n",
    "blanks=[]\n",
    "for index,Sentence,Polarity in df.itertuples():\n",
    "    if type(Sentence)==str:\n",
    "        if Sentence.isspace():\n",
    "            blanks.append(index)\n",
    "print(blanks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.505417\n",
       "1    0.494583\n",
       "Name: Polarity, dtype: float64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking distribution in target feature.No imbalance\n",
    "df['Polarity'].value_counts()/len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#NAME?\n",
      "#NAME?\n",
      "#NAME?\n",
      "#NAME?\n"
     ]
    }
   ],
   "source": [
    "for rows in df[\"Sentence\"]:\n",
    "    if re.findall(r'\\#NAME',rows):\n",
    "        print(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing those useless columns that Excel marked as #NAME?\n",
    "df.drop(df[df[\"Sentence\"]==\"#NAME?\"].index, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textstat\n",
    "sid=SentimentIntensityAnalyzer()\n",
    "\n",
    "def doc_length(corpus):\n",
    "    return np.array([len(doc)-doc.count(\" \") for doc in corpus]).reshape(-1, 1)\n",
    "\n",
    "def lexicon_count(corpus):\n",
    "    return np.array([textstat.lexicon_count(doc) for doc in corpus]).reshape(-1, 1)\n",
    "\n",
    "def flesch_reading_ease(corpus):\n",
    "    return np.array([textstat.flesch_reading_ease(doc) for doc in corpus]).reshape(-1, 1)\n",
    "\n",
    "def automated_readability(corpus):\n",
    "    return np.array([textstat.automated_readability_index(doc) for doc in corpus]).reshape(-1, 1)\n",
    "\n",
    "#found % of words that are capitalized thinking maybe positive reviews have more often capitalization\n",
    "def get_caps(doc):\n",
    "    return sum([1 for char in doc if char.isupper()])\n",
    "    \n",
    "def capitalized_count(corpus):\n",
    "    return np.array([get_caps(doc) for doc in corpus]).reshape(-1, 1)\n",
    "\n",
    "def get_digit(doc):\n",
    "    return sum([1 for char in doc if char.isdigit()])\n",
    "\n",
    "def digit_count(corpus):\n",
    "    return np.array([get_digit(doc) for doc in corpus]).reshape(-1, 1)\n",
    "\n",
    "def get_punctuation(doc):\n",
    "    return sum([1 for char in doc if char in string.punctuation])\n",
    "\n",
    "def punctuation_count(corpus):\n",
    "    return np.array([get_punctuation(doc) for doc in corpus]).reshape(-1, 1)\n",
    "\n",
    "def num_exclamation_marks(corpus):\n",
    "    return np.array([doc.count('!') for doc in corpus]).reshape(-1, 1)\n",
    "\n",
    "def extract_smile(corpus):\n",
    "    return np.array([bool(re.search(\":\\)|:\\(|;\\)\", doc.lower())) for doc in corpus]).reshape(-1, 1)\n",
    "\n",
    "def string_search(corpus):\n",
    "    return np.array([bool(re.search(\"recommend|love|is the best|amazing\", doc.lower())) for doc in corpus]).reshape(-1, 1)\n",
    "\n",
    "def sentiment(corpus):\n",
    "    return np.array([sid.polarity_scores(doc)[\"compound\"] for doc in corpus]).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "import unidecode\n",
    "import textstat\n",
    "import string  \n",
    "\n",
    "lemmer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english') + stopwords.words('spanish'))\n",
    "\n",
    "def clean_text(doc):\n",
    "    \n",
    "    doc=BeautifulSoup(doc, [\"lxml\"]).get_text()\n",
    "    \n",
    "    # Lowercase and remove punctuation\n",
    "    doc = \"\".join([char.lower() for char in doc if char not in string.punctuation])\n",
    "    \n",
    "    # Replace URL with URL string\n",
    "    doc=re.sub(r'http\\S+|www\\S+', '', doc).strip()\n",
    "    \n",
    "    # Replace AT with AT string\n",
    "    doc = re.sub(r'@', 'AT', doc)\n",
    "    \n",
    "    # Replace all numbers/digits \n",
    "    doc= re.sub(r'\\d+', '', doc)\n",
    "    \n",
    "    #tokenize\n",
    "    doc=re.split('\\W+', doc.strip()) \n",
    "    \n",
    "    #unidecode\n",
    "    doc=[unidecode.unidecode(tokens) for tokens in doc]\n",
    "        \n",
    "    # Lemmatize each word.\n",
    "    doc = ' '.join([lemmer.lemmatize(w) for w in doc ]) \n",
    "        \n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df['Sentence']\n",
    "y = df['Polarity']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Method      Time        F1  Accuracy  Rank\n",
      "2        RF  2.858246  0.841391  0.841667     1\n",
      "0        LR  1.788133  0.832916  0.833333     2\n",
      "5       GBC  2.211996  0.822355  0.822917     3\n",
      "3  Adaboost  2.514186  0.803949  0.804167     4\n",
      "1        DT  1.595626  0.797452  0.797917     5\n",
      "4       SVM  3.205747  0.476849  0.556250     6\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.feature_extraction import stop_words\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import time\n",
    "\n",
    "# This vectorizer will be used to create the BOW features\n",
    "vectorizer = TfidfVectorizer(preprocessor=clean_text, \n",
    "                             max_features = 1000, \n",
    "                             ngram_range=[1,4],\n",
    "                             stop_words=None,\n",
    "                             strip_accents=\"unicode\", \n",
    "                             lowercase=False, max_df=0.8, min_df=0.02,use_idf=True)\n",
    "\n",
    "lr = LogisticRegression(random_state=42) \n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "gb=xgboost.XGBClassifier(random_state=42)\n",
    "rf = RandomForestClassifier(random_state=42, n_estimators=200)\n",
    "ada = AdaBoostClassifier(random_state=42, n_estimators=200)\n",
    "svm=SVC(random_state=42,probability=True)\n",
    "\n",
    "\n",
    "feature_processing =  FeatureUnion([ \n",
    "    ('bow', Pipeline([('cv', vectorizer),])),\n",
    "    ('length', FunctionTransformer(doc_length, validate=False)),\n",
    "    ('words', FunctionTransformer(lexicon_count, validate=False)),\n",
    "    ('flesch_reading_ease', FunctionTransformer(flesch_reading_ease, validate=False)),\n",
    "    ('automated_readability', FunctionTransformer(automated_readability, validate=False)),    \n",
    "    ('punctuation_count', FunctionTransformer(punctuation_count, validate=False)),\n",
    "    ('capital_count', FunctionTransformer(capitalized_count, validate=False)),\n",
    "    ('digit_count', FunctionTransformer(digit_count, validate=False)),\n",
    "    ('has_smile', FunctionTransformer(extract_smile, validate=False)),\n",
    "    ('num_exclamation_marks', FunctionTransformer(num_exclamation_marks, validate=False)),  \n",
    "    ('has_string', FunctionTransformer(string_search, validate=False)),  \n",
    "    ('sentiment', FunctionTransformer(sentiment, validate=False)),\n",
    "])\n",
    "\n",
    "classifiers = {\n",
    "    \"LR\": lr, \n",
    "    \"DT\": dt,\n",
    "    \"RF\": rf,\n",
    "    \"Adaboost\": ada,\n",
    "    \"SVM\":svm,\n",
    "    \"GBC\": gb\n",
    "}\n",
    "\n",
    "model_results = list()\n",
    "    \n",
    "for model_name,model in classifiers.items():\n",
    "    start = time.time()\n",
    "    pipe = Pipeline([('features', feature_processing), ('classifier', model)])\n",
    "    fitting=pipe.fit(X_train,y_train)\n",
    "    end = time.time()\n",
    "    total = end - start\n",
    "    y_pred=fitting.predict(X_test)\n",
    "    f1=f1_score(y_test, y_pred, average='macro')\n",
    "    accuracy=accuracy_score(y_test, y_pred)\n",
    "     \n",
    "    df_results = pd.DataFrame({\"Method\": [model_name],\n",
    "                               \"Time\" : [total],\n",
    "                               \"F1\" : [f1],\n",
    "                               \"Accuracy\":[accuracy]\n",
    "                             })\n",
    "    model_results.append(df_results)\n",
    "    \n",
    "    dataset_results = pd.concat([m for m in model_results], axis = 0).reset_index() \n",
    "    dataset_results = dataset_results.drop(columns = \"index\",axis =1)\n",
    "    dataset_results = dataset_results.sort_values(by=['F1'], ascending=False)\n",
    "    dataset_results['Rank'] = range(1, len(dataset_results)+1)\n",
    "print(dataset_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[211  35]\n",
      " [ 50 184]]\n",
      "\n",
      "F1 Score = 0.82292\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.86      0.83       246\n",
      "           1       0.84      0.79      0.81       234\n",
      "\n",
      "    accuracy                           0.82       480\n",
      "   macro avg       0.82      0.82      0.82       480\n",
      "weighted avg       0.82      0.82      0.82       480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "y_pred = pipe.predict(X_test)\n",
    "\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\nF1 Score = {:.5f}\".format(f1_score(y_test, y_pred, average=\"micro\")))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier__C': 1e-05, 'classifier__max_iter': 200, 'classifier__penalty': 'none'}\n",
      "0.8376795039164492\n",
      "{'classifier__max_depth': 5, 'classifier__max_features': 50}\n",
      "0.8100182223672758\n",
      "{'classifier__criterion': 'gini', 'classifier__max_depth': 12, 'classifier__max_features': 25, 'classifier__n_estimators': 100}\n",
      "0.8340187119234116\n",
      "{'classifier__learning_rate': 0.1, 'classifier__n_estimators': 200}\n",
      "0.8293312119234116\n",
      "{'classifier__learning_rate': 0.1, 'classifier__n_estimators': 150}\n",
      "0.8293230526544821\n",
      "     Method         Time        F1  Accuracy  Rank\n",
      "3  Adaboost   171.849932  0.832843  0.833333     1\n",
      "0        LR   307.198583  0.830926  0.831250     2\n",
      "2        RF  2469.851460  0.826534  0.827083     3\n",
      "4       GBC   157.729462  0.826450  0.827083     4\n",
      "1        DT   129.945246  0.813703  0.814583     5\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(preprocessor=clean_text, \n",
    "                             max_features = 1000, \n",
    "                             ngram_range=[1,4],\n",
    "                             stop_words=None,\n",
    "                             strip_accents=\"unicode\", \n",
    "                             lowercase=False, max_df=0.8, min_df=0.02,use_idf=True)\n",
    "\n",
    "lr = LogisticRegression(random_state=42) \n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "gb=xgboost.XGBClassifier(random_state=42)\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "ada = AdaBoostClassifier(random_state=42, n_estimators=200)\n",
    "svm=SVC(random_state=42,probability=True)\n",
    "\n",
    "\n",
    "feature_processing =  FeatureUnion([ \n",
    "    ('bow', Pipeline([('cv', vectorizer),])),\n",
    "    ('length', FunctionTransformer(doc_length, validate=False)),\n",
    "    ('words', FunctionTransformer(lexicon_count, validate=False)),\n",
    "    ('flesch_reading_ease', FunctionTransformer(flesch_reading_ease, validate=False)),\n",
    "    ('automated_readability', FunctionTransformer(automated_readability, validate=False)),    \n",
    "    ('punctuation_count', FunctionTransformer(punctuation_count, validate=False)),\n",
    "    ('capital_count', FunctionTransformer(capitalized_count, validate=False)),\n",
    "    ('digit_count', FunctionTransformer(digit_count, validate=False)),\n",
    "    ('has_smile', FunctionTransformer(extract_smile, validate=False)),\n",
    "    ('num_exclamation_marks', FunctionTransformer(num_exclamation_marks, validate=False)),  \n",
    "    ('has_string', FunctionTransformer(string_search, validate=False)),  \n",
    "    ('sentiment', FunctionTransformer(sentiment, validate=False)),\n",
    "])\n",
    "\n",
    "classifiers = {\n",
    "     \"LR\": lr, \n",
    "     \"DT\": dt,\n",
    "     \"RF\": rf,\n",
    "     \"Adaboost\": ada,\n",
    "     \"GBC\": gb\n",
    "}\n",
    "\n",
    "model_results = list()\n",
    "    \n",
    "for model_name,model in classifiers.items():\n",
    "    start = time.time()    \n",
    "    pipeline = Pipeline(steps=[('preprocess',feature_processing),\n",
    "                               ('classifier',model)])\n",
    "    \n",
    "    if model==rf:\n",
    "        param_grid = { \n",
    "        'classifier__max_features': [25,50, 200, 500, 1000],\n",
    "        'classifier__max_depth':[1,2,5,8,10,12,15,20],\n",
    "        'classifier__n_estimators': [100, 200,300],\n",
    "        'classifier__criterion':[\"gini\",\"entropy\"]\n",
    "    }\n",
    "        \n",
    "    elif model==lr:\n",
    "        param_grid = { \n",
    "           'classifier__C':np.logspace(-5,1,2,8,10),\n",
    "           'classifier__max_iter':[50,100,200,300,400],\n",
    "           'classifier__penalty':[\"l1\",\"l2\",\"elasticnet\",\"none\"]\n",
    "    }\n",
    "    elif model==dt:\n",
    "        param_grid = { \n",
    "        'classifier__max_features': [50, 200, 500],\n",
    "        'classifier__max_depth':[1,2,5,10,15,20]\n",
    "    }\n",
    "    elif model==ada:\n",
    "        param_grid = { \n",
    "        'classifier__learning_rate': [0.01,0.1,0.5,1],\n",
    "        'classifier__n_estimators':[50,100,150,200]\n",
    "    }\n",
    "    elif model==gb:\n",
    "        param_grid_gb = { \n",
    "        'classifier__learning_rate': [0.05, 0.10, 0.15, 0.20, 0.25, 0.30] ,\n",
    "        'classifier__max_depth': [ 3, 4, 5, 6, 8, 10, 12, 15],\n",
    "        'classifier__n_estimators':[50,100,150,200]\n",
    "    }\n",
    "    \n",
    "    pipeline = Pipeline(steps=[('preprocess',feature_processing),\n",
    "                               ('classifier',model)])\n",
    "\n",
    "    \n",
    "    CV = GridSearchCV(pipeline, param_grid, n_jobs= 1)\n",
    "                  \n",
    "    fitted=CV.fit(X_train, y_train)  \n",
    "    print(CV.best_params_)    \n",
    "    print(CV.best_score_)\n",
    "    \n",
    "    end = time.time()\n",
    "    total = end - start\n",
    "    \n",
    "    y_pred=fitted.predict(X_test)\n",
    "    f1=f1_score(y_test, y_pred, average='macro')\n",
    "    accuracy=accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    df_results = pd.DataFrame({\"Method\": [model_name],\n",
    "                               \"Time\" : [total],\n",
    "                               \"F1\" : [f1],\n",
    "                               \"Accuracy\":[accuracy]\n",
    "                             })\n",
    "    model_results.append(df_results)\n",
    "\n",
    "    dataset_results = pd.concat([m for m in model_results], axis = 0).reset_index() \n",
    "    dataset_results = dataset_results.drop(columns = \"index\",axis =1)\n",
    "    dataset_results = dataset_results.sort_values(by=['F1'], ascending=False)\n",
    "    dataset_results['Rank'] = range(1, len(dataset_results)+1)\n",
    "print(dataset_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8270833333333333"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__learning_rate': 0.1, 'classifier__n_estimators': 150}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitted.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitted=CV.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(steps=[('preprocess',feature_processing),\n",
    "                               ('classifier',AdaBoostClassifier(learning_rate= 0.1, n_estimators=150,random_state=42))])\n",
    "fit=pipeline.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the feature processing pipeline, so I can use it later\n",
    "feature_processing_obj = pipeline.named_steps['preprocess']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"datasets/sentiment_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_test = feature_processing_obj.transform(df_test['Sentence']).todense()\n",
    "pred_test = pipeline.predict(df_test['Sentence'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
